{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HD_Survival_Analysis\n",
    "generates fits from lifelines package, saves those fits as data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lifelines as lil\n",
    "from lifelines import KaplanMeierFitter\n",
    "import os\n",
    "import sys\n",
    "from bokeh.plotting import ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import Range1d\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST = True\n",
    "DATA_DIR = \"data/\"\n",
    "DATA_FOLDERS = [\"2014\",\"2015\",\"data_Q1_2016\",\"data_Q2_2016\",\"data_Q3_2016\",\"data_Q4_2016\"]\n",
    "SUMMARY_DIR = \"summary_data/\"\n",
    "PERCENT_TOTAL_REQ = .05\n",
    "FAILURE_RATE_REQ = 5\n",
    "MIN_NUMBER_REQ = 100\n",
    "INPUT_DIR = \"survival_data\"\n",
    "OUTPUT_DIR = \"web/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_models = []\n",
    "for df in DATA_FOLDERS:\n",
    "    print(SUMMARY_DIR + df + '.csv')\n",
    "    summary_dats = pd.read_csv(SUMMARY_DIR + df + '.csv', header=0, nrows=200)\n",
    "    summary_dats = summary_dats.sort_values(by=\"percent_total\", ascending=False)\n",
    "    clipped1 = summary_dats[summary_dats['percent_total'] >= PERCENT_TOTAL_REQ]\n",
    "    clipped2 = summary_dats[(summary_dats['failure_rate'] >= FAILURE_RATE_REQ) & (summary_dats['drive_count'] >= MIN_NUMBER_REQ)]\n",
    "    [target_models.append(m) for m in clipped1['model']]\n",
    "    [target_models.append(m) for m in clipped2['model']]\n",
    "\n",
    "unique_target_models = np.unique(target_models)\n",
    "print(unique_target_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survival_data = []\n",
    "km_data = []\n",
    "for model in unique_target_models:\n",
    "    model_ns = model.replace(\" \", \"_\")\n",
    "    pf = INPUT_DIR + \"/survival_\" +  model_ns + '.csv'# + \"data_Q2_2016.csv\"\n",
    "    print(pf)\n",
    "    tmp = pd.read_csv(pf, header=0)\n",
    "    yr = 365. * 24.\n",
    "    tmp['runtime_max'] = tmp['runtime_max']/yr\n",
    "    tmp['uptime'] = tmp['uptime']/yr\n",
    "    tmp['runtime_min'] = tmp['runtime_min']/yr\n",
    "    survival_data.append(tmp)\n",
    "    km = lil.KaplanMeierFitter()\n",
    "    try:\n",
    "        km.fit(durations=tmp['runtime_max'], event_observed=tmp['failure'], entry=tmp['runtime_min'])\n",
    "        km_data.append(km)\n",
    "        s = km.survival_function_\n",
    "        ci = km.confidence_interval_\n",
    "        i = s.index\n",
    "        s = s.iloc[:,0].values\n",
    "        u = ci.iloc[:,0].values\n",
    "        l = ci.iloc[:,1].values\n",
    "        tmp = pd.DataFrame(np.asarray([i,s]).T, columns = ['time','surv'])\n",
    "        tmp.to_csv(OUTPUT_DIR + \"/kmfit_alt\" + model_ns + \".csv\", index = False)\n",
    "    except:\n",
    "        print(\"Probably too few early truncation times and too many events. Try BreslowFlemingHarringtonFitter?\")\n",
    "        print(\"Skipping ...\")\n",
    "        pass\n",
    "#         time = s['KM_estimate'].index\n",
    "#         surv = s['KM_estimate'].values\n",
    "#         surv_upper = ci['KM_estimate_upper_0.95'].values\n",
    "#         surv_lower = ci['KM_estimate_lower_0.95'].values\n",
    "#         kdl = zip(time,surv,surv_upper, surv_lower)\n",
    "#         model_km = pd.DataFrame(kdl, columns=[\"time\", \"surv\", \"surv_lower\", \"surv_upper\"])\n",
    "        \n",
    "#         km_outf = OUTPUT_DIR + \"/kmfit_\" + model_ns + \".csv\",\n",
    "#         #print km_outf\n",
    "#         model_km.to_csv(OUTPUT_DIR + \"/kmfit_\" + model_ns + \".csv\", index = False)\n",
    "#     except:\n",
    "#         print \"Probably too few early truncation times and too many events. Try BreslowFlemingHarringtonFitter?\"\n",
    "#         print \"Skipping ...\"\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def km_bokeh_plot(kms, models):\n",
    "    surv_plt1 = figure(title=\"Survival Analysis\", tools=['hover,box_zoom,wheel_zoom,save,reset'])\n",
    "    hover = surv_plt1.select(dict(type=HoverTool))\n",
    "    hover.tooltips = [\n",
    "        (\"Model \", \"@model\"),\n",
    "        (\"Time \", \"@timeline\"),\n",
    "        (\"survival fraction \", \"@km_surv\"),\n",
    "        (\"upper 95% bound \", \"@surv_upper\"),\n",
    "        (\"lower 95% bound \", \"@surv_lower\")\n",
    "        ]\n",
    "    if len(kms) > 1:\n",
    "        hover.mode = 'mouse'\n",
    "    else: \n",
    "        hover.mode = 'vline'\n",
    "    colors = ['#1a1334', '#03c383', '#fbbf45', '#ed0345' ,  '#26294a', '#aad962', '#01545a', '#ef6a32','#017351',\n",
    "              '#a12a5e', '#710162', '#110141']\n",
    "    n = 0\n",
    "    for km in kms:\n",
    "        s = km.survival_function_\n",
    "        ci = km.confidence_interval_\n",
    "        #time = s['KM_estimate'].index\n",
    "        #surv = s['KM_estimate'].values\n",
    "        #surv_upper = ci['KM_estimate_upper_0.95'].values\n",
    "        #surv_lower = ci['KM_estimate_lower_0.95'].values\n",
    "        \n",
    "        time = s.index\n",
    "        surv = s.iloc[:,0].values\n",
    "        surv_upper = ci.iloc[:,0].values\n",
    "        surv_lower = ci.iloc[:,1].values\n",
    "        \n",
    "        band_x = np.append(time, time[::-1])\n",
    "        band_y = np.append(surv_upper, surv_lower[::-1])\n",
    "        source = ColumnDataSource(\n",
    "            data=dict(\n",
    "                timeline=[i for i in time],\n",
    "                km_surv=[i for i in surv],\n",
    "                model=[models[n] for i in time],\n",
    "                surv_lower=[i for i in surv_lower],\n",
    "                surv_upper=[i for i in surv_upper]\n",
    "            )\n",
    "        )\n",
    "        surv_plt1.patch(band_x, band_y, color=colors[n], fill_alpha=0.2)\n",
    "        surv_plt1.line('timeline', 'km_surv', line_width = 2, alpha=.8, source = source, legend=models[n], color=colors[n])\n",
    "        n += 1\n",
    "    surv_plt1.xaxis.axis_label = 'Time (Years)'\n",
    "    surv_plt1.yaxis.axis_label = 'Kaplan-Meier Estimation (survival fraction)'\n",
    "    surv_plt1.grid.grid_line_alpha = 0\n",
    "    surv_plt1.ygrid.band_fill_color = \"grey\"\n",
    "    surv_plt1.ygrid.band_fill_alpha = 0.2\n",
    "    surv_plt1.x_range.range_padding = 0\n",
    "    surv_plt1.legend.location = \"bottom_left\"\n",
    "    surv_plt1.plot_height = 500\n",
    "    surv_plt1.plot_width = 700\n",
    "    surv_plt1.min_border_left = 80\n",
    "    surv_plt1.outline_line_width = 1\n",
    "    surv_plt1.outline_line_alpha = 0.3\n",
    "    surv_plt1.y_range = Range1d(0.0, 1.02)\n",
    "    show(surv_plt1)\n",
    "         \n",
    "#km_bokeh_plot(km_data, unique_target_models)\n",
    "km_bokeh_plot(km_data[0:6], unique_target_models[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazard rates with Nelson-Aalen\n",
    " * The failure rate is the total number of failures within a population, divided by the total time expended by that population, during a particular measurement interval.\n",
    " * The hazard function or hazard rate is the failure rate calculated instantaneously.  \n",
    " * The cumulative hazard curve is a basic tool: it is the sum of failure rate estimates so it is much more stable than the point-wise instananeous estimates.\n",
    " * The hazard curve has a catch: the derivation involves a smoothing kernel smoother applied to the differences of the cumulative hazard curve), and thus it has a free parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lifelines import NelsonAalenFitter\n",
    "naf = NelsonAalenFitter()\n",
    "seagate = survival.loc[survival['model'] == model_map['ST4000DM000']]\n",
    "naf.fit(seagate['runtime_max'], seagate['failure'], entry=seagate['runtime_min'], label='Seagate ST4000DM000')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, squeeze=False, sharex=True, sharey=True)\n",
    "naf.plot(ax=axes[0,0],title=\"Cumulative Hazard Rate\")\n",
    "plt.show()\n",
    "\n",
    "haz = naf.smoothed_hazard_\n",
    "smoothing_bandwidth_time=1.2\n",
    "q = haz(smoothing_bandwidth_time)\n",
    "mean_haz = np.mean( q[q.columns[0]])\n",
    "\n",
    "ax = naf.plot_hazard(bandwidth=smoothing_bandwidth_time, title = \"Hazard Rate\")\n",
    "ax.axhline(mean_haz , ls='--', lw=1.0, color='black')\n",
    "haz_str = str(100*np.round(mean_haz,4)) + \"%\"\n",
    "ax.annotate(haz_str, color='black', xy=(0.01,mean_haz), xytext=(10,4), textcoords='offset points')\n",
    "plt.show()\n",
    "print(\"The failure rate for these seagate drives is %s\" % haz_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
