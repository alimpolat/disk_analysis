{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX\n",
      "data_Q1_2016.zip\n",
      "data_Q1_2016\n",
      "Shape of hd data:  (72800, 96)\n",
      "There are 1157 unique drives. \n",
      "There are 30 unique models. \n",
      "There are 91 unique dates. \n",
      "There are 5 failures.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import sys\n",
    "#import math\n",
    "#import struct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.feature_selection import SelectFromModel\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "TEST = True\n",
    "DATA_DIR = \"data/\"\n",
    "dir = \"data/data_Q1_2016/\"\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    print(file)\n",
    "\n",
    "#yr = '2016'\n",
    "hd = pd.DataFrame()\n",
    "for file in os.listdir(dir): # loading 78 indivual data files\n",
    "    temp = pd.read_csv(dir+file, header=0,nrows=800) # my laptop is struggling to handle more rows\n",
    "    hd = hd.append(temp)\n",
    "print(\"Shape of hd data: \", np.shape(hd))\n",
    "print(\"There are %d unique drives. \" % hd['serial_number'].value_counts().count())\n",
    "print(\"There are %d unique models. \" % hd['model'].value_counts().count())\n",
    "print(\"There are %d unique dates. \" % hd['date'].value_counts().count())\n",
    "print(\"There are %d failures.\" % hd['failure'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capacity_tb\n",
      "-1.000000e-12         2\n",
      " 8.002636e-02       363\n",
      " 1.374390e-01         1\n",
      " 1.600419e-01      2376\n",
      " 2.500000e-01        91\n",
      " 2.500594e-01       942\n",
      " 3.200729e-01      1187\n",
      " 5.001079e-01     10524\n",
      " 1.000205e+00       650\n",
      " 1.500302e+00      1181\n",
      " 2.000399e+00     53640\n",
      " 3.000593e+00     81170\n",
      " 4.000787e+00    547560\n",
      " 5.000981e+00       479\n",
      " 6.001175e+00     27554\n",
      " 8.001563e+00       280\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def tb_capacity(x):\n",
    "    \"\"\"\n",
    "    1 gig is np.power(2, 30) bytes, but maybe it is 10^9 bytes. Who you asking? Whatever.\n",
    "    \"\"\"\n",
    "    tb = np.power(10, 12)\n",
    "    #if not math.isnan(x):\n",
    "    return x/tb\n",
    "\n",
    "hd.capacity_bytes = hd.capacity_bytes.map(tb_capacity)\n",
    "hd.rename(columns={'capacity_bytes': 'capacity_tb'}, inplace=True)\n",
    "print(hd.groupby('capacity_tb').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp = pd.to_datetime(hd.loc[:, 'date'])\n",
    "#tmp2 = tmp.dt.dayofyear\n",
    "#hd.rename(columns={'date': 'day_of_year'}, inplace=True)\n",
    "##print(hd.loc[:, 'date'])\n",
    "#print(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388331, 96)\n",
      "capacity_tb  has a NaN fraction of:\t\t\t 0.0\n",
      "date  has a NaN fraction of:\t\t\t 0.0\n",
      "failure  has a NaN fraction of:\t\t\t 0.0\n",
      "model  has a NaN fraction of:\t\t\t 0.0\n",
      "serial_number  has a NaN fraction of:\t\t\t 0.0\n",
      "smart_10_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_10_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_12_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_12_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_183_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_183_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_184_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_184_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_187_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_187_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_188_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_188_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_189_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_189_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_190_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_190_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_191_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_191_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_192_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_192_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_193_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_193_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_194_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_194_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_197_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_197_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_198_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_198_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_199_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_199_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_1_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_1_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_240_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_240_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_241_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_241_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_242_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_242_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_3_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_3_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_4_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_4_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_5_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_5_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_7_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_7_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_9_normalized  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "smart_9_raw  has a NaN fraction of:\t\t\t 7.72536830693e-06\n",
      "(388331, 53)\n",
      "Index(['capacity_tb', 'date', 'failure', 'model', 'serial_number',\n",
      "       'smart_10_normalized', 'smart_10_raw', 'smart_12_normalized',\n",
      "       'smart_12_raw', 'smart_183_normalized', 'smart_183_raw',\n",
      "       'smart_184_normalized', 'smart_184_raw', 'smart_187_normalized',\n",
      "       'smart_187_raw', 'smart_188_normalized', 'smart_188_raw',\n",
      "       'smart_189_normalized', 'smart_189_raw', 'smart_190_normalized',\n",
      "       'smart_190_raw', 'smart_191_normalized', 'smart_191_raw',\n",
      "       'smart_192_normalized', 'smart_192_raw', 'smart_193_normalized',\n",
      "       'smart_193_raw', 'smart_194_normalized', 'smart_194_raw',\n",
      "       'smart_197_normalized', 'smart_197_raw', 'smart_198_normalized',\n",
      "       'smart_198_raw', 'smart_199_normalized', 'smart_199_raw',\n",
      "       'smart_1_normalized', 'smart_1_raw', 'smart_240_normalized',\n",
      "       'smart_240_raw', 'smart_241_normalized', 'smart_241_raw',\n",
      "       'smart_242_normalized', 'smart_242_raw', 'smart_3_normalized',\n",
      "       'smart_3_raw', 'smart_4_normalized', 'smart_4_raw',\n",
      "       'smart_5_normalized', 'smart_5_raw', 'smart_7_normalized',\n",
      "       'smart_7_raw', 'smart_9_normalized', 'smart_9_raw'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hd = pd.DataFrame.copy(hd[hd['model'] == 'ST4000DM000']) # select only the most common seagate model\n",
    "print(np.shape(hd))\n",
    "# Some columns have just a few NaNs, while others are all NaNs\n",
    "# drop columns of all nan\n",
    "hd_clean = hd.dropna(axis=1, how='all')\n",
    "# but lets avoid losing columns that potentially have lots of information\n",
    "# in particular if the fraction of nans is greater than nan_frac, then drop\n",
    "nan_frac = .3\n",
    "for ikey in hd_clean.keys():\n",
    "    tmp = hd_clean[ikey].isnull().sum()\n",
    "    print(ikey, \" has a NaN fraction of:\\t\\t\\t\", tmp/len(hd_clean))\n",
    "    if tmp/len(hd_clean) >= nan_frac:\n",
    "        hdcl = hd_clean.drop(ikey, 1)\n",
    "\n",
    "# put zeros in the NaN locations we kept\n",
    "hd_clean = hd_clean.fillna(0)\n",
    "\n",
    "for ikey in hd_clean.keys():\n",
    "    tmp = hd_clean[ikey].isnull().sum()\n",
    "    if tmp > 0:\n",
    "        print(\"Warning, there shouldn't be any NaNs but there are in %s\" % ikey)\n",
    "\n",
    "y = hd_clean.failure\n",
    "print(np.shape(hd_clean))\n",
    "print(hd_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388331, 27)\n",
      "Index(['date', 'failure', 'serial_number', 'smart_10_raw', 'smart_12_raw',\n",
      "       'smart_183_raw', 'smart_184_raw', 'smart_187_raw', 'smart_188_raw',\n",
      "       'smart_189_raw', 'smart_190_raw', 'smart_191_raw', 'smart_192_raw',\n",
      "       'smart_193_raw', 'smart_194_raw', 'smart_197_raw', 'smart_198_raw',\n",
      "       'smart_199_raw', 'smart_1_raw', 'smart_240_raw', 'smart_241_raw',\n",
      "       'smart_242_raw', 'smart_3_raw', 'smart_4_raw', 'smart_5_raw',\n",
      "       'smart_7_raw', 'smart_9_raw'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def clip_by_column_txt(df, col_txt):\n",
    "    for ikey in df.keys():\n",
    "        if col_txt not in ikey and ikey != 'serial_number' and ikey != 'failure' and ikey != 'date':\n",
    "            del df[ikey]\n",
    "        \n",
    "#serial_number = hd_clean['serial_number']\n",
    "#failure = hd_clean['failure']\n",
    "clip_by_column_txt(hd_clean,\"raw\") # selected columns and those that have \"raw\"\n",
    "\n",
    "print(np.shape(hd_clean))\n",
    "#print(np.shape(serial_number))\n",
    "#print(np.shape(failure))\n",
    "print(hd_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aggregations = {\n",
    "#     'smart_9_raw': { # smart 9 is the disk uptime\n",
    "#         'runtime_max': 'max',  \n",
    "#         'runtime_min': 'min',\n",
    "#         'uptime': lambda x: max(x) - min(x)  \n",
    "#     },\n",
    "#     'failure': {\n",
    "#      'failure': 'sum'\n",
    "#     }  \n",
    "# }\n",
    "# survival = hd_clean.groupby('serial_number').agg(aggregations).reset_index()\n",
    "# survival.columns = survival.columns.droplevel()\n",
    "# survival = survival.loc[survival['failure'] <=1 ] # if the sum of failures is gt 1 then then drive's data is wonky\n",
    "# survival['runtime_max'] = survival['runtime_max']/8760.0 # hrs to yrs\n",
    "# survival['runtime_min'] = survival['runtime_min']/8760.0\n",
    "#print(survival['failure'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(serial_number.unique().counts())\n",
    "#print(hd['serial_number'].value_counts().count())\n",
    "#print(serial_number.value_counts().count())\n",
    "#print(np.shape(serial_number.unique()))\n",
    "#unique_serial_numbers = serial_number.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001\n"
     ]
    }
   ],
   "source": [
    "print(hd_clean['serial_number'].value_counts().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to group all observations that relate to a single HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serial_grouped = hd_clean.groupby(['serial_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "serial_grouped = list(serial_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "serial_data_dir = 'serial_data/'\n",
    "for i in range((len(serial_grouped))):\n",
    "    fname = serial_data_dir + serial_grouped[i][0] + '.csv'\n",
    "    indiv_serial_data = serial_grouped[i][1]\n",
    "    f=open(fname,'w')\n",
    "    f.write(\"#\"+ str(np.shape(indiv_serial_data)) + \"\\n#\")\n",
    "    f.close()\n",
    "    del  indiv_serial_data['serial_number']    \n",
    "    indiv_serial_data = indiv_serial_data.sort_values(by=['smart_9_raw']) \n",
    "    indiv_serial_data.to_csv(path_or_buf=fname, sep=',', header=True, index=False, mode='a', encoding='utf-8') # change mode to 'a' to append)\n",
    "    if i>= 1000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
